{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 07:  Topic Modeling with Latent Semantic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "import math\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latent Semantic Analysis (LSA) is a method for finding latent similarities between documents treated as a bag of words by using a low rank approximation. It is used for document classification, clustering and retrieval. For example, LSA can be used to search for prior art given a new patent application. In this homework, we will implement a small library for simple latent semantic analysis as a practical example of the application of SVD. The ideas are very similar to PCA. SVD is also used in recommender systems in an similar fashion (for an SVD-based recommender system library, see [Surpise](http://surpriselib.com)). \n",
    "\n",
    "We will implement a toy example of LSA to get familiar with the ideas. If you want to use LSA or similar methods for statistical language analysis, the most efficient Python libraries are probably [gensim](https://radimrehurek.com/gensim/) and [spaCy](https://spacy.io) - these also provide an online algorithm - i.e. the training information can be continuously updated. Other useful functions for processing natural language can be found in the [Natural Language Toolkit](http://www.nltk.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: The SVD from scipy.linalg performs a full decomposition, which is inefficient since we only need to decompose until we get the first k singluar values. If the SVD from `scipy.linalg` is too slow, please use the `sparsesvd` function from the [sparsesvd](https://pypi.python.org/pypi/sparsesvd/) package to perform SVD instead.  You can install in the usual way with \n",
    "```\n",
    "!pip install sparsesvd\n",
    "```\n",
    "\n",
    "Then import the following\n",
    "```python\n",
    "from sparsesvd import sparsesvd \n",
    "from scipy.sparse import csc_matrix \n",
    "```\n",
    "\n",
    "and use as follows\n",
    "```python\n",
    "sparsesvd(csc_matrix(M), k=10)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1 (20 points)**.  Calculating pairwise distance matrices.\n",
    "\n",
    "Suppose we want to construct a distance matrix between the rows of a matrix. For example, given the matrix \n",
    "\n",
    "```python\n",
    "M = np.array([[1,2,3],[4,5,6]])\n",
    "```\n",
    "\n",
    "the distance matrix using Euclidean distance as the measure would be\n",
    "```python\n",
    "[[ 0.000  1.414  2.828]\n",
    " [ 1.414  0.000  1.414]\n",
    " [ 2.828  1.414  0.000]] \n",
    "```\n",
    "if $M$ was a collection of column vectors.\n",
    "\n",
    "Write a function to calculate the pairwise-distance matrix given the matrix $M$ and some arbitrary distance function. Your functions should have the following signature:\n",
    "```\n",
    "def func_name(M, distance_func):\n",
    "    pass\n",
    "```\n",
    "\n",
    "0. Write a distance function for the Euclidean, squared Euclidean and cosine measures.\n",
    "1. Write the function using looping for M as a collection of row vectors.\n",
    "2. Write the function using looping for M as a collection of column vectors.\n",
    "3. Write the function using broadcasting for M as a collection of row vectors.\n",
    "4. Write the function using broadcasting for M as a collection of column vectors. \n",
    "\n",
    "For 3 and 4, try to avoid using transposition (but if you get stuck, there will be no penalty for using transposition)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by defining M exactly as it is in the instructions above (which makes it a collection of row vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = np.array([[1,2,3],[4,5,6]])\n",
    "M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a distance function for the Euclidean, squared Euclidean, and cosine measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sq_euclid(v1, v2):\n",
    "    \"\"\"Calculate pairwise squared Euclidean distances between two input vectors\"\"\"\n",
    "    return np.square(v1 - v2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclid(v1, v2):\n",
    "    \"\"\"Calculate pairwise Euclidean distances between two input vectors\"\"\"\n",
    "    return np.sqrt(sq_euclid(v1, v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_dist(v1, v2):\n",
    "    return 1 - (v1 @ v2.T) / (np.linalg.norm(v1) * np.linalg.norm(v2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the function using looping for M as a collection of row vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def part2(M, distance_func):\n",
    "    \"\"\"Compute specified distance metric between rows of M, where M is specified as a collection of row vectors\"\"\"\n",
    "    result = np.zeros(shape = (M.shape[0], M.shape[0]))\n",
    "    for i in range(M.shape[0]):\n",
    "        for j in range(i + 1, M.shape[0]):\n",
    "            result[i, j] = distance_func(M[i, :], M[j, :])\n",
    "    return result + result.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean distance\n",
      "[[0.    5.196]\n",
      " [5.196 0.   ]]\n",
      "Squared euclidean distance\n",
      "[[ 0. 27.]\n",
      " [27.  0.]]\n",
      "Cosine distance\n",
      "[[0.    0.025]\n",
      " [0.025 0.   ]]\n"
     ]
    }
   ],
   "source": [
    "# Euclidean distance\n",
    "print(\"Euclidean distance\")\n",
    "print(np.round(part2(M, euclid), decimals = 3))\n",
    "\n",
    "# Squared euclidean distance\n",
    "print(\"Squared euclidean distance\")\n",
    "print(np.round(part2(M, sq_euclid), decimals = 3))\n",
    "\n",
    "# Cosine distance\n",
    "print(\"Cosine distance\")\n",
    "print(np.round(part2(M, cos_dist), decimals = 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the function using looping for M as a collection of column vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*A solution using transposition* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def part3(M, distance_func):\n",
    "    \"\"\"Compute specified distance metric between rows of M, where M is specified as a collection of column vectors\"\"\"\n",
    "    return part2(M.T, distance_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean distance\n",
      "[[0.    1.414 2.828]\n",
      " [1.414 0.    1.414]\n",
      " [2.828 1.414 0.   ]]\n",
      "Squared euclidean distance\n",
      "[[0. 2. 8.]\n",
      " [2. 0. 2.]\n",
      " [8. 2. 0.]]\n",
      "Cosine distance\n",
      "[[0.    0.009 0.024]\n",
      " [0.009 0.    0.003]\n",
      " [0.024 0.003 0.   ]]\n"
     ]
    }
   ],
   "source": [
    "# Euclidean distance\n",
    "print(\"Euclidean distance\")\n",
    "print(np.round(part3(M, euclid), decimals = 3))\n",
    "\n",
    "# Squared euclidean distance\n",
    "print(\"Squared euclidean distance\")\n",
    "print(np.round(part3(M, sq_euclid), decimals = 3))\n",
    "\n",
    "# Cosine distance\n",
    "print(\"Cosine distance\")\n",
    "print(np.round(part3(M, cos_dist), decimals = 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*A solution without transposition*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def part3_2(M, distance_func):\n",
    "    \"\"\"Compute specified distance metric between rows of M, where M is specified as a collection of column vectors\"\"\"\n",
    "    result = np.zeros(shape = (M.shape[1], M.shape[1]))\n",
    "    for i in range(M.shape[1]):\n",
    "        for j in range(i + 1, M.shape[1]):\n",
    "            result[i, j] = distance_func(M[:, i], M[:, j])\n",
    "    return result + result.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean distance\n",
      "[[0.    1.414 2.828]\n",
      " [1.414 0.    1.414]\n",
      " [2.828 1.414 0.   ]]\n",
      "Squared euclidean distance\n",
      "[[0. 2. 8.]\n",
      " [2. 0. 2.]\n",
      " [8. 2. 0.]]\n",
      "Cosine distance\n",
      "[[0.    0.009 0.024]\n",
      " [0.009 0.    0.003]\n",
      " [0.024 0.003 0.   ]]\n"
     ]
    }
   ],
   "source": [
    "# Euclidean distance\n",
    "print(\"Euclidean distance\")\n",
    "print(np.round(part3_2(M, euclid), decimals = 3))\n",
    "\n",
    "# Squared euclidean distance\n",
    "print(\"Squared euclidean distance\")\n",
    "print(np.round(part3_2(M, sq_euclid), decimals = 3))\n",
    "\n",
    "# Cosine distance\n",
    "print(\"Cosine distance\")\n",
    "print(np.round(part3_2(M, cos_dist), decimals = 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the function using broadcasting for M as a collection of row vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  0,  0],\n",
       "        [ 3,  3,  3]],\n",
       "\n",
       "       [[-3, -3, -3],\n",
       "        [ 0,  0,  0]]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = (M[None, :] - M[:, None])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  0],\n",
       "        [ 1,  1],\n",
       "        [ 2,  2]],\n",
       "\n",
       "       [[-1, -1],\n",
       "        [ 0,  0],\n",
       "        [ 1,  1]],\n",
       "\n",
       "       [[-2, -2],\n",
       "        [-1, -1],\n",
       "        [ 0,  0]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2 = (M.T[None, :] - M.T[:, None])\n",
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def part4(M, distance_func):\n",
    "    \"\"\"Compute specified distance metric between rows of M (using broadcasting), \n",
    "    \n",
    "    where M is specified as a collection of column vectors\"\"\"\n",
    "    \n",
    "    # Calculate rows differences using broadcasting\n",
    "    dists = M[None, :] - M[:, None]\n",
    "    \n",
    "    # Calculate specified distance matric\n",
    "    result = np.zeros(shape = (M.shape[0], M.shape[0]))\n",
    "    for i in range(dists.shape[0]):\n",
    "        for j in range(i + 1, dists.shape[0]):\n",
    "            result[i, j] = distance_func(dists[i, 0, :], dists[i, j, :])\n",
    "    return result + result.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0., nan],\n",
       "       [nan,  0.]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There's a bug for cos_dist\n",
    "part4(M, cos_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.   , 1.414, 2.828],\n",
       "       [1.414, 0.   , 1.414],\n",
       "       [2.828, 1.414, 0.   ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.sqrt(np.square(M.T[None, :] - M.T[:, None]).sum(axis = -1)), decimals = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.   , 5.196],\n",
       "       [5.196, 0.   ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.sqrt(np.square(M[None, :] - M[:, None]).sum(axis = -1)), decimals = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2 (20 points)**. Write 3 functions to calculate the term frequency (tf), the inverse document frequency (idf) and the product (tf-idf). Each function should take a single argument `docs`, which is a dictionary of (key=identifier, value=document text) pairs, and return an appropriately sized array. Convert '-' to ' ' (space), remove punctuation, convert text to lowercase and split on whitespace to generate a collection of terms from the document text.\n",
    "\n",
    "- tf = the number of occurrences of term $i$ in document $j$\n",
    "- idf = $\\log \\frac{n}{1 + \\text{df}_i}$ where $n$ is the total number of documents and $\\text{df}_i$ is the number of documents in which term $i$ occurs.\n",
    "\n",
    "Print the table of tf-idf values for the following document collection\n",
    "\n",
    "```\n",
    "s1 = \"The quick brown fox\"\n",
    "s2 = \"Brown fox jumps over the jumps jumps jumps\"\n",
    "s3 = \"The the the lazy dog elephant.\"\n",
    "s4 = \"The the the the the dog peacock lion tiger elephant\"\n",
    "\n",
    "docs = {'s1': s1, 's2': s2, 's3': s3, 's4': s4}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_text(doc):\n",
    "    \"\"\"Formats text from a single document\"\"\"\n",
    "    doc = doc.translate(str.maketrans('-', ' ')).lower()\n",
    "    return doc.translate(str.maketrans('', '', string.punctuation)).split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_tf(docs):\n",
    "    \"\"\"Calculate term frequency for all documents in the input\"\"\"\n",
    "    \n",
    "    # Find all unique words in docs\n",
    "    words = np.unique(format_text(str(list(docs.values()))))\n",
    "    \n",
    "    # Initialize output array and column counter\n",
    "    result = np.zeros(shape = (len(words), len(list(docs.keys()))))\n",
    "    col = 0\n",
    "    \n",
    "    # For each document, count words, and assign to tf-matrix\n",
    "    for doc in docs:\n",
    "        counted_words = Counter(format_text(docs[doc]))\n",
    "        for word in counted_words.elements():\n",
    "            row = np.where(words == word)\n",
    "            result[row, col] = counted_words[word]\n",
    "        col += 1\n",
    "    \n",
    "    # Return result\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_idf(docs):\n",
    "    \"\"\"Calculate inverse document frequency\"\"\"\n",
    "    \n",
    "    # Find all unique words in docs\n",
    "    words = np.unique(format_text(str(list(docs.values()))))\n",
    "    \n",
    "    # Initialize output array\n",
    "    df_i = np.zeros(len(words))\n",
    "    \n",
    "    # Determine number of documents in input\n",
    "    n = len(list(docs.keys()))\n",
    "    \n",
    "    # Calculate df_i\n",
    "    for doc in docs:\n",
    "        words_unique = np.unique(format_text(docs[doc]))\n",
    "        for word in words_unique:\n",
    "            index = np.where(words == word)\n",
    "            df_i[index] += 1\n",
    "    \n",
    "    # Return idf\n",
    "    return (np.log(n / (1 + df_i))).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 0., 0.],\n",
       "       [0., 0., 1., 1.],\n",
       "       [0., 0., 1., 1.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [0., 4., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 1., 3., 5.],\n",
       "       [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_tf(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.28768207],\n",
       "       [ 0.28768207],\n",
       "       [ 0.28768207],\n",
       "       [ 0.28768207],\n",
       "       [ 0.69314718],\n",
       "       [ 0.69314718],\n",
       "       [ 0.69314718],\n",
       "       [ 0.69314718],\n",
       "       [ 0.69314718],\n",
       "       [ 0.69314718],\n",
       "       [-0.22314355],\n",
       "       [ 0.69314718]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_idf(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary for testing\n",
    "s1 = \"The quick brown fox\"\n",
    "s2 = \"Brown fox jumps over the jumps jumps jumps\"\n",
    "s3 = \"The the the lazy dog elephant.\"\n",
    "s4 = \"The the the the the dog peacock lion tiger elephant\"\n",
    "\n",
    "docs = {'s1': s1, 's2': s2, 's3': s3, 's4': s4}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3 (20 points)**. \n",
    "\n",
    "1. Write a function that takes a matrix $M$ and an integer $k$ as arguments, and reconstructs a reduced matrix using only the $k$ largest singular values. Use the `scipy.linagl.svd` function to perform the decomposition. This is the least squares approximation to the matrix $M$ in $k$ dimensions.\n",
    "\n",
    "2. Apply the function you just wrote to the following term-frequency matrix for a set of $9$ documents using $k=2$ and print the reconstructed matrix $M'$.\n",
    "```\n",
    "M = np.array([[1, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "       [1, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "       [1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 1, 1, 0, 1, 0, 0, 0, 0],\n",
    "       [0, 1, 1, 2, 0, 0, 0, 0, 0],\n",
    "       [0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
    "       [0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
    "       [0, 0, 1, 1, 0, 0, 0, 0, 0],\n",
    "       [0, 1, 0, 0, 0, 0, 0, 0, 1],\n",
    "       [0, 0, 0, 0, 0, 1, 1, 1, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 1, 1]])\n",
    "```\n",
    "\n",
    "3. Calculate the pairwise correlation matrix for the original matrix M and the reconstructed matrix using $k=2$ singular values (you may use [scipy.stats.spearmanr](http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.spearmanr.html) to do the calculations). Consider the first 5 sets of documents as one group $G1$ and the last 4 as another group $G2$ (i.e. first 5 and last 4 columns). What is the average within group correlation for $G1$, $G2$ and the average cross-group correlation for G1-G2 using either $M$ or $M'$. (Do not include self-correlation in the within-group calculations.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4 (40 points)**. Clustering with LSA\n",
    "\n",
    "1. Begin by loading a PubMed database of selected article titles using 'pickle'. With the following:\n",
    "```import pickle\n",
    "docs = pickle.load(open('pubmed.pic', 'rb'))```\n",
    "\n",
    "    Create a tf-idf matrix for every term that appears at least once in any of the documents. What is the shape of the tf-idf matrix? \n",
    "\n",
    "2. Perform SVD on the tf-idf matrix to obtain $U \\Sigma V^T$ (often written as $T \\Sigma D^T$ in this context with $T$ representing the terms and $D$ representing the documents). If we set all but the top $k$ singular values to 0, the reconstructed matrix is essentially $U_k \\Sigma_k V_k^T$, where $U_k$ is $m \\times k$, $\\Sigma_k$ is $k \\times k$ and $V_k^T$ is $k \\times n$. Terms in this reduced space are represented by $U_k \\Sigma_k$ and documents by $\\Sigma_k V^T_k$. Reconstruct the matrix using the first $k=10$ singular values.\n",
    "\n",
    "3. Use agglomerative hierarchical clustering with complete linkage to plot a dendrogram and comment on the likely number of  document clusters with $k = 100$. Use the dendrogram function from [SciPy ](https://docs.scipy.org/doc/scipy-0.15.1/reference/generated/scipy.cluster.hierarchy.dendrogram.html).\n",
    "\n",
    "4. Determine how similar each of the original documents is to the new document `data/mystery.txt`. Since $A = U \\Sigma V^T$, we also have $V = A^T U S^{-1}$ using orthogonality and the rule for transposing matrix products. This suggests that in order to map the new document to the same concept space, first find the tf-idf vector $v$ for the new document - this must contain all (and only) the terms present in the existing tf-idx matrix. Then the query vector $q$ is given by $v^T U_k \\Sigma_k^{-1}$. Find the 10 documents most similar to the new document and the 10 most dissimilar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes on the Pubmed articles**\n",
    "\n",
    "These were downloaded with the following script.\n",
    "\n",
    "```python\n",
    "from Bio import Entrez, Medline\n",
    "Entrez.email = \"YOUR EMAIL HERE\"\n",
    "import cPickle\n",
    "\n",
    "try:\n",
    "    docs = cPickle.load(open('pubmed.pic'))\n",
    "except Exception, e:\n",
    "    print e\n",
    "\n",
    "    docs = {}\n",
    "    for term in ['plasmodium', 'diabetes', 'asthma', 'cytometry']:\n",
    "        handle = Entrez.esearch(db=\"pubmed\", term=term, retmax=50)\n",
    "        result = Entrez.read(handle)\n",
    "        handle.close()\n",
    "        idlist = result[\"IdList\"]\n",
    "        handle2 = Entrez.efetch(db=\"pubmed\", id=idlist, rettype=\"medline\", retmode=\"text\")\n",
    "        result2 = Medline.parse(handle2)\n",
    "        for record in result2:\n",
    "            title = record.get(\"TI\", None)\n",
    "            abstract = record.get(\"AB\", None)\n",
    "            if title is None or abstract is None:\n",
    "                continue\n",
    "            docs[title] = '\\n'.join([title, abstract])\n",
    "            print title\n",
    "        handle2.close()\n",
    "    cPickle.dump(docs, open('pubmed.pic', 'w'))\n",
    "docs.values()\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
